✅ PART 1 — THEORETICAL ANALYSIS (30%)
Q1. Explain how AI-driven code generation tools reduce development time. What are their limitations?

Answer:
AI code generation tools such as GitHub Copilot reduce development time by automatically suggesting code snippets, functions, comments, and boilerplate structure as developers type. They learn from existing patterns in large codebases, enabling them to generate solutions quickly, reducing repetitive work, and allowing developers to focus on high-level logic. These tools also speed up prototyping and reduce time spent on debugging by offering context-aware suggestions.

However, their limitations include:

Accuracy issues — suggestions may be incorrect, inefficient, or insecure.

Over-reliance — developers might accept generated code without fully understanding it.

Limited domain context — the tool cannot fully grasp business rules or project-specific constraints.

Potential security risks — may suggest unsafe or copyrighted code patterns.

Bias from training data — the model reflects biases found in the data it was trained on.

Q2. Compare supervised and unsupervised learning in the context of automated bug detection.

Answer:
In automated bug detection:

Supervised Learning

Uses labeled data where examples are tagged as “bug” or “no bug.”

Can achieve high accuracy when large, clean datasets are available.

Useful for predicting known bug patterns.

Limitation: cannot detect new, unseen bug types not present in training data.

Unsupervised Learning

Works on unlabeled data.

Identifies anomalies, unusual code patterns, or suspicious program behavior.

Effective for detecting unknown or rare bugs.

Limitation: may produce false positives because it doesn’t know what actual bugs look like.

Together, they form a powerful hybrid system for automated bug detection.

Q3. Why is bias mitigation critical when using AI for user experience personalization?

Answer:
Personalization algorithms learn from user data, which often contains patterns influenced by gender, age, culture, or economic bias. Without mitigation, AI might treat users unfairly—for example, recommending different features or options based on discriminatory patterns. This can lead to exclusion, lack of diversity, and unethical user experiences.

Bias mitigation ensures fairness, equal access, transparency, and compliance with legal standards such as GDPR. It improves trust, reduces discrimination, and ensures that recommendations reflect actual user needs rather than harmful historical patterns.

Case Study: AIOps — How does it improve deployment efficiency? (2 Examples)

Answer:
AIOps improves deployment efficiency by applying AI and automation to DevOps processes:

1. Predictive Failure Detection

AIOps can analyze logs, metrics, and events to predict system failures before they happen.
This reduces deployment downtime by allowing proactive fixes.

2. Automated Rollbacks & Scaling

AIOps tools can automatically detect abnormal behavior after deployment and trigger rollback or microservice scaling.
This prevents broken releases from affecting users.

Overall, AIOps reduces manual intervention, accelerates release cycles, and increases system reliability.
